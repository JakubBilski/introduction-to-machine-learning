{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpodcast-o-rybach\u001b[0m (\u001b[33mpodcast-o-rybach-warsaw-university-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch transformations for loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name, input_resolution):\n",
    "    if name == 'FER2013':\n",
    "        mean, std = (0.5, ), (0.5, )\n",
    "    elif name == 'EuroSAT':\n",
    "        mean, std = (0.5, ), (0.5, )\n",
    "    elif name == 'FashionMNIST':\n",
    "        mean, std = (0.286, ), (0.338, )\n",
    "    elif name == 'imagenette':\n",
    "        mean, std = (0.462, 0.458, 0.430), (0.270, 0.267, 0.290)\n",
    "    elif name == 'imagewoof':\n",
    "        mean, std = (0.486, 0.456, 0.394), (0.248, 0.241, 0.250)\n",
    "    input_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((input_resolution, input_resolution)),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    if name == 'FER2013':\n",
    "        trainset = torchvision.datasets.FER2013(\n",
    "            './data',\n",
    "            transform=input_transform\n",
    "        )\n",
    "        valset = torchvision.datasets.FER2013(\n",
    "            './data',\n",
    "            transform=input_transform,\n",
    "            split='test'\n",
    "        )\n",
    "        is_grayscale = True\n",
    "        class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    if name == 'FashionMNIST':\n",
    "        trainset = torchvision.datasets.FashionMNIST(\n",
    "            './data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=input_transform\n",
    "        )\n",
    "        valset = torchvision.datasets.FashionMNIST(\n",
    "            './data',\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=input_transform\n",
    "        )\n",
    "        is_grayscale = True\n",
    "        class_names = trainset.classes\n",
    "    elif name == 'EuroSAT':\n",
    "        dataset = torchvision.datasets.EuroSAT(\n",
    "            './data',\n",
    "            download=True,\n",
    "            transform=input_transform\n",
    "        )\n",
    "        trainset, valset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "        is_grayscale = False\n",
    "        class_names = dataset.classes\n",
    "    elif name == 'imagewoof':\n",
    "        trainset = torchvision.datasets.ImageFolder(\n",
    "            './data/imagewoof2-160/train',\n",
    "            transform=input_transform\n",
    "        )\n",
    "        valset = torchvision.datasets.ImageFolder(\n",
    "            './data/imagewoof2-160/val',\n",
    "            transform=input_transform\n",
    "        )\n",
    "        is_grayscale = False\n",
    "        class_names = trainset.classes\n",
    "    elif name == 'imagenette':\n",
    "        trainset = torchvision.datasets.Imagenette(\n",
    "            './data/imagenette_train',\n",
    "            split='train',\n",
    "            size='160px',\n",
    "            transform=input_transform\n",
    "        )\n",
    "        valset = torchvision.datasets.Imagenette(\n",
    "            './data/imagenette_val',\n",
    "            split='val',\n",
    "            size='160px',\n",
    "            transform=input_transform\n",
    "        )\n",
    "        is_grayscale = False\n",
    "        class_names = trainset.classes\n",
    "    return trainset, valset, is_grayscale, class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurCNN(nn.Module):\n",
    "    def __init__(self, input_is_grayscale, num_outputs):\n",
    "        super(OurCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 if input_is_grayscale else 3, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 96, 3)\n",
    "        self.conv3 = nn.Conv2d(96, 128, 3)\n",
    "        self.pool_last = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool_last(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class OurCNNDropout(nn.Module):\n",
    "    def __init__(self, input_is_grayscale, num_outputs):\n",
    "        super(OurCNNDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 if input_is_grayscale else 3, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 96, 3)\n",
    "        self.conv3 = nn.Conv2d(96, 128, 3)\n",
    "        self.pool_last = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 200)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(100, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool_last(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(self.dropout1(x)))\n",
    "        x = self.fc3(self.dropout2(x))\n",
    "        return x\n",
    "\n",
    "class OurCNNBatchNormAfterConvs(nn.Module):\n",
    "    def __init__(self, input_is_grayscale, num_outputs):\n",
    "        super(OurCNNBatchNormAfterConvs, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 if input_is_grayscale else 3, 64, 5, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 96, 3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.conv3 = nn.Conv2d(96, 128, 3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool_last = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool_last(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class OurCNNBatchNorm(nn.Module):\n",
    "    def __init__(self, input_is_grayscale, num_outputs):\n",
    "        super(OurCNNBatchNorm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 if input_is_grayscale else 3, 64, 5, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 96, 3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.conv3 = nn.Conv2d(96, 128, 3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool_last = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 200, bias=False)\n",
    "        self.bnfc1 = nn.BatchNorm1d(200)\n",
    "        self.fc2 = nn.Linear(200, 100, bias=False)\n",
    "        self.bnfc2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool_last(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = F.relu(self.bnfc1(self.fc1(x)))\n",
    "        x = F.relu(self.bnfc2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class OurCNNVGGLike(nn.Module):\n",
    "    def __init__(self, input_is_grayscale, num_outputs):\n",
    "        super(OurCNNVGGLike, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 if input_is_grayscale else 3, 64, 3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 96, 3)\n",
    "        self.conv4 = nn.Conv2d(96, 96, 3)\n",
    "        self.conv5 = nn.Conv2d(96, 96, 3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.conv6 = nn.Conv2d(96, 128, 3)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool_last = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 200)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(100, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv2(self.conv1(x)))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv5(self.conv4(self.conv3(x))))))\n",
    "        x = self.pool_last(F.relu(self.bn3(self.conv7(self.conv6(x)))))\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(self.dropout1(x)))\n",
    "        x = self.fc3(self.dropout2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train. Save loss and accuracy for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, valloader, criterion, optimizer, scheduler, num_epochs):\n",
    "\n",
    "    model.to(device)\n",
    "    PRINT_STEP = len(trainloader) // 5 - 1\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            correct += (predictions == labels).float().mean().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % PRINT_STEP == PRINT_STEP-1:\n",
    "                accuracy = correct / PRINT_STEP\n",
    "                loss = running_loss / PRINT_STEP\n",
    "                step = epoch * len(trainloader) + i\n",
    "                wandb.log({\n",
    "                        \"train/accuracy\": accuracy,\n",
    "                        \"train/loss\": loss\n",
    "                    },\n",
    "                    step=step\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for j, data in enumerate(valloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                val_correct += (predictions == labels).float().mean().item()\n",
    "\n",
    "        accuracy = val_correct / len(valloader)\n",
    "        loss = val_loss / len(valloader)\n",
    "        wandb.log({\n",
    "                \"validation/accuracy\": accuracy,\n",
    "                \"validation/loss\": loss\n",
    "            },\n",
    "            step = (epoch + 1) * len(trainloader)\n",
    "        )\n",
    "        model.train()\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 train and 62 val batches\n",
      "classes: [('tench', 'Tinca tinca'), ('English springer', 'English springer spaniel'), ('cassette player',), ('chain saw', 'chainsaw'), ('church', 'church building'), ('French horn', 'horn'), ('garbage truck', 'dustcart'), ('gas pump', 'gasoline pump', 'petrol pump', 'island dispenser'), ('golf ball',), ('parachute', 'chute')]\n",
      "770494 learnable parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:djwq4ygm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▆█</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>0.69682</td></tr><tr><td>train/loss</td><td>0.8246</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-grass-125</strong> at: <a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2/runs/djwq4ygm' target=\"_blank\">https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2/runs/djwq4ygm</a><br/> View project at: <a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2' target=\"_blank\">https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241110_114716-djwq4ygm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:djwq4ygm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\iml2\\2024\\wandb\\run-20241110_115653-wycl0ag5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2/runs/wycl0ag5' target=\"_blank\">swift-violet-126</a></strong> to <a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2' target=\"_blank\">https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2/runs/wycl0ag5' target=\"_blank\">https://wandb.ai/podcast-o-rybach-warsaw-university-of-technology/iml_lab2/runs/wycl0ag5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "LR_DECAY = 0.95\n",
    "MOMENTUM = 0.9\n",
    "LEARNING_RATE = 0.03\n",
    "OPTMIZER = optim.SGD\n",
    "\n",
    "for MODEL in [OurCNNVGGLike, OurCNNDropout, OurCNNBatchNormAfterConvs, OurCNNBatchNorm]:\n",
    "    for DATASET_NAME in ['imagenette', 'imagewoof']:\n",
    "        if MODEL == OurCNNBatchNormAfterConvs and DATASET_NAME != 'imagewoof':\n",
    "            continue\n",
    "        if DATASET_NAME == 'imagewoof':\n",
    "            LEARNING_RATE = 0.01\n",
    "        INPUT_RESOLUTION = 80\n",
    "        trainset, valset, input_is_grayscale, class_names = load_dataset(\n",
    "            DATASET_NAME, INPUT_RESOLUTION\n",
    "        )\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            batch_size=64,\n",
    "            num_workers=2,\n",
    "            shuffle=True\n",
    "        )\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "            valset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "        print(f'Found {len(trainloader)} train and {len(valloader)} val batches')\n",
    "        print(f'classes: {class_names}')\n",
    "\n",
    "        model = MODEL(input_is_grayscale, len(class_names))\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = OPTMIZER(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=LR_DECAY)\n",
    "        num_learnable_parameters = sum([\n",
    "            p.numel() for p in model.parameters() if p.requires_grad\n",
    "        ])\n",
    "        print(f'{num_learnable_parameters} learnable parameters')\n",
    "        wandb.init(\n",
    "            project=\"iml_lab2\",\n",
    "            config={\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"learning_rate_decay\": LR_DECAY,\n",
    "                \"momentum\": MOMENTUM,\n",
    "                \"batch_size\": trainloader.batch_size,\n",
    "                \"input_resolution\": INPUT_RESOLUTION,\n",
    "                \"num_parameters\": num_learnable_parameters,\n",
    "                \"optimizer\": OPTMIZER.__name__,\n",
    "                \"architecture\": MODEL.__name__,\n",
    "                \"dataset\": DATASET_NAME\n",
    "            }\n",
    "        )\n",
    "        train(model, trainloader, valloader, criterion, optimizer, scheduler, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate means and standard deviations for Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST:\n",
      "[0.28594527]\n",
      "[0.3380673]\n",
      "imagenette:\n",
      "[0.46247163 0.45796242 0.42979676]\n",
      "[0.27013233 0.26697868 0.29031703]\n",
      "imagewoof:\n",
      "[0.4860626  0.45593935 0.39390635]\n",
      "[0.24799196 0.2409045  0.24982297]\n"
     ]
    }
   ],
   "source": [
    "for DATASET_NAME in ['FashionMNIST', 'imagenette', 'imagewoof']:\n",
    "    mean, std = 0.0, 0.0\n",
    "    num_samples = 0\n",
    "    INPUT_RESOLUTION = 80\n",
    "    trainset, valset, input_is_grayscale, class_names = load_dataset(\n",
    "        DATASET_NAME, INPUT_RESOLUTION\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=64,\n",
    "        num_workers=2,\n",
    "        shuffle=True\n",
    "    )\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        mean = inputs.numpy().mean(axis=(0, 2, 3)) * inputs.shape[0] + mean\n",
    "        std = np.std(inputs.numpy(), axis=(0, 2, 3)) * inputs.shape[0] + std\n",
    "        num_samples += inputs.shape[0]\n",
    "    print(f'{DATASET_NAME}:')\n",
    "    print(mean / num_samples)\n",
    "    print(std / num_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_predicted = []\n",
    "with torch.no_grad():\n",
    "    for j, data in enumerate(valloader, 0):\n",
    "        inputs, labels = data\n",
    "        y_true.extend(labels.numpy())\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        y_predicted.extend(predictions.cpu().numpy())\n",
    "model.train()\n",
    "\n",
    "\n",
    "confusion_matrix = wandb.plot.confusion_matrix(\n",
    "    probs=None,\n",
    "    y_true=y_true,\n",
    "    preds=y_predicted,\n",
    "    class_names=class_names\n",
    ")\n",
    "wandb.log({\n",
    "    \"conf_mat\" : confusion_matrix\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET_NAME in ['imagenette', 'imagewoof']:\n",
    "    table_data = []\n",
    "    if DATASET_NAME == 'imagenette':\n",
    "        train_dir = 'data/imagenette_train/imagenette2-160/train'\n",
    "    elif DATASET_NAME == 'imagewoof':\n",
    "        train_dir = 'data/imagewoof2-160/train'\n",
    "    trainset, valset, input_is_grayscale, actual_class_names = load_dataset(\n",
    "        DATASET_NAME, 80\n",
    "    )\n",
    "    for i, class_name in enumerate(os.listdir(train_dir)):\n",
    "        for file_name in os.listdir(train_dir + '/' + class_name)[:10]:\n",
    "            if not file_name.endswith('png'):\n",
    "                continue\n",
    "            filepath = f'{train_dir}/{class_name}/{file_name}'\n",
    "            table_data.append([file_name, actual_class_names[i], wandb.Image(filepath)])\n",
    "    columns = [\"filename\", \"class\", \"image\"]\n",
    "    test_table = wandb.Table(data=table_data, columns=columns)\n",
    "    wandb.log(f'example_samples_{DATASET_NAME}', test_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurCNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1200, out_features=40, bias=True)\n",
       "  (fc2): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_data = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for j, data in enumerate(valloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        val_correct += (predictions == labels).float().mean().item()\n",
    "        for i in np.argwhere((predictions != labels).cpu().numpy()):\n",
    "            np_image = inputs[i].cpu().numpy()[0]\n",
    "            misclassified_data.append((\n",
    "                np_image,\n",
    "                predictions[i].item(),\n",
    "                labels[i].item()\n",
    "            ))\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(dataiter)\n",
    "\n",
    "for image, true_label, selected_label in misclassified_data[11:12]:\n",
    "    plt.imshow(np.transpose(image / 2 + 0.5, (1, 2, 0)), cmap='grey')\n",
    "    plt.title(f'true: {class_names[true_label]} predicted: {class_names[selected_label]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.22352946,  0.4431373 ,  0.5529412 , ...,  0.2313726 ,\n",
       "            0.20784318,  0.17647064],\n",
       "          [ 0.14509809,  0.427451  ,  0.56078434, ...,  0.26274514,\n",
       "            0.20784318,  0.17647064],\n",
       "          [ 0.05882359,  0.3803922 ,  0.5294118 , ...,  0.2941177 ,\n",
       "            0.26274514,  0.21568632],\n",
       "          ...,\n",
       "          [-0.78039217, -0.8039216 , -0.8352941 , ...,  0.4039216 ,\n",
       "            0.37254906,  0.35686278],\n",
       "          [-0.77254903, -0.85882354, -0.827451  , ...,  0.38823533,\n",
       "            0.34901965,  0.32549024],\n",
       "          [-0.8352941 , -0.8901961 , -0.81960785, ...,  0.34901965,\n",
       "            0.30980396,  0.26274514]]]], dtype=float32),\n",
       " 4,\n",
       " 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
